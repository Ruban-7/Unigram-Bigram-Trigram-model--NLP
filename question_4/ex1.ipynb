{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\ruban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\ruban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\ruban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " import nltk\n",
    " nltk.download(\"brown\")\n",
    " nltk.download(\"webtext\")\n",
    " nltk.download(\"reuters\")\n",
    " from nltk.corpus import brown, webtext, reuters\n",
    " brown_corpus = brown.sents()\n",
    " brown_corpus = [\" \".join(sentence) for sentence in brown_corpus]\n",
    " brown_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in brown_corpus][:5000]\n",
    " webtext_corpus = webtext.sents()\n",
    " webtext_corpus = [\" \".join(sentence) for sentence in webtext_corpus]\n",
    " webtext_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in webtext_corpus][:5000]\n",
    " reuters_corpus = reuters.sents()\n",
    " reuters_corpus = [\" \".join(sentence) for sentence in reuters_corpus]\n",
    " reuters_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in reuters_corpus][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize text into unigrams\n",
    "def generate_unigrams(text):\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract unigrams, bigrams, and trigrams from a corpus\n",
    "def brown_unigrams(corpus):\n",
    "    unigrams = []\n",
    "    for sentence in corpus:\n",
    "        unigrams.extend(generate_unigrams(sentence))\n",
    "    return unigrams\n",
    "\n",
    "def brown_bigrams(unigrams):\n",
    "    return list(zip(unigrams, unigrams[1:]))\n",
    "\n",
    "def brown_trigrams(unigrams):\n",
    "    return list(zip(unigrams, unigrams[1:], unigrams[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract unigrams, bigrams, and trigrams from a corpus\n",
    "def webtext_unigrams(corpus):\n",
    "    unigrams = []\n",
    "    for sentence in corpus:\n",
    "        unigrams.extend(generate_unigrams(sentence))\n",
    "    return unigrams\n",
    "\n",
    "def webtext_bigrams(unigrams):\n",
    "    return list(zip(unigrams, unigrams[1:]))\n",
    "\n",
    "def webtext_trigrams(unigrams):\n",
    "    return list(zip(unigrams, unigrams[1:], unigrams[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating n-grams for Brown corpus\n",
    "unigram_brown = brown_unigrams(brown_corpus)\n",
    "bigrams_brown = brown_bigrams(unigram_brown)\n",
    "trigrams_brown = brown_trigrams(unigram_brown)\n",
    "\n",
    "# Generating n-grams for Webtext corpus\n",
    "unigram_webtext = webtext_unigrams(webtext_corpus)\n",
    "bigrams_webtext = webtext_bigrams(unigram_webtext)\n",
    "trigrams_webtext = webtext_trigrams(unigram_webtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams from Brown Corpus: [('<s>', 'The'), ('The', 'Fulton'), ('Fulton', 'County'), ('County', 'Grand'), ('Grand', 'Jury'), ('Jury', 'said'), ('said', 'Friday'), ('Friday', 'an'), ('an', 'investigation'), ('investigation', 'of')]\n",
      "Trigrams from Brown Corpus: [('<s>', 'The', 'Fulton'), ('The', 'Fulton', 'County'), ('Fulton', 'County', 'Grand'), ('County', 'Grand', 'Jury'), ('Grand', 'Jury', 'said'), ('Jury', 'said', 'Friday'), ('said', 'Friday', 'an'), ('Friday', 'an', 'investigation'), ('an', 'investigation', 'of'), ('investigation', 'of', \"Atlanta's\")]\n",
      "Bigrams from Webtext Corpus: [('<s>', 'Cookie'), ('Cookie', 'Manager'), ('Manager', ':'), (':', '\"'), ('\"', 'Don'), ('Don', \"'\"), (\"'\", 't'), ('t', 'allow'), ('allow', 'sites'), ('sites', 'that')]\n",
      "Trigrams from Webtext Corpus: [('<s>', 'Cookie', 'Manager'), ('Cookie', 'Manager', ':'), ('Manager', ':', '\"'), (':', '\"', 'Don'), ('\"', 'Don', \"'\"), ('Don', \"'\", 't'), (\"'\", 't', 'allow'), ('t', 'allow', 'sites'), ('allow', 'sites', 'that'), ('sites', 'that', 'set')]\n"
     ]
    }
   ],
   "source": [
    "# Printing the required n-gram outputs\n",
    "print(\"Bigrams from Brown Corpus:\", bigrams_brown[:10])\n",
    "print(\"Trigrams from Brown Corpus:\", trigrams_brown[:10])\n",
    "print(\"Bigrams from Webtext Corpus:\", bigrams_webtext[:10])\n",
    "print(\"Trigrams from Webtext Corpus:\", trigrams_webtext[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to count token frequencies\n",
    "def count_frequencies(tokens):\n",
    "    return Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to count n-gram frequencies\n",
    "def count_ngram_frequencies(ngrams):\n",
    "    return Counter(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get count of a specific n-gram\n",
    "def get_ngram_count(ngram, ngram_list):\n",
    "    return ngram_list.count(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional probability for bigrams\n",
    "def bigram_probability(w1, w2, bigram_list, unigram_list):\n",
    "    bigram = (w1, w2)\n",
    "    bigram_count = get_ngram_count(bigram, bigram_list)\n",
    "    unigram_count = unigram_list.count(w1)\n",
    "    return (bigram_count + 1) / (unigram_count + len(set(unigram_list)))\n",
    "\n",
    "# Conditional probability for trigrams\n",
    "def trigram_probability(w1, w2, w3, trigram_list, bigram_list, unigram_list):\n",
    "    trigram = (w1, w2, w3)\n",
    "    trigram_count = get_ngram_count(trigram, trigram_list)\n",
    "    bigram_count = get_ngram_count((w1, w2), bigram_list)\n",
    "    return (trigram_count + 1) / (bigram_count + len(set(unigram_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the next word using bigrams\n",
    "def predict_next_word_bigram(word, bigram_list):\n",
    "    candidates = [pair for pair in bigram_list if pair[0] == word]\n",
    "    if not candidates:\n",
    "        return None\n",
    "    return max(candidates, key=lambda x: bigram_list.count(x))[1]\n",
    "\n",
    "# Function to predict the next word using trigrams\n",
    "def predict_next_word_trigram(w1, w2, trigram_list):\n",
    "    candidates = [triplet for triplet in trigram_list if triplet[0] == w1 and triplet[1] == w2]\n",
    "    if not candidates:\n",
    "        return None\n",
    "    return max(candidates, key=lambda x: trigram_list.count(x))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word after 'The': President\n"
     ]
    }
   ],
   "source": [
    "# Example sentence prediction using bigrams\n",
    "start_word = \"The\"\n",
    "next_word = predict_next_word_bigram(start_word, bigrams_brown)\n",
    "print(f\"Predicted next word after '{start_word}': {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word after 'The': \"\n"
     ]
    }
   ],
   "source": [
    "# Example sentence prediction using bigrams\n",
    "start_word = \"The\"\n",
    "next_word = predict_next_word_bigram(start_word, bigrams_webtext)\n",
    "print(f\"Predicted next word after '{start_word}': {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word after 'The man': was\n"
     ]
    }
   ],
   "source": [
    "# Example sentence prediction using trigrams\n",
    "first_word = \"The\"\n",
    "second_word = \"man\"\n",
    "next_word = predict_next_word_trigram(first_word, second_word, trigrams_brown)\n",
    "print(f\"Predicted next word after '{first_word} {second_word}': {next_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word after 'The man': None\n"
     ]
    }
   ],
   "source": [
    "# Example sentence prediction using trigrams\n",
    "first_word = \"The\"\n",
    "second_word = \"man\"\n",
    "next_word = predict_next_word_trigram(first_word, second_word, trigrams_webtext)\n",
    "print(f\"Predicted next word after '{first_word} {second_word}': {next_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
