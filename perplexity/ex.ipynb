{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\ruban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\ruban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\ruban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ruban\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"webtext\")\n",
    "nltk.download(\"reuters\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import brown, webtext, reuters\n",
    "brown_corpus = brown.sents()\n",
    "brown_corpus = [\" \".join(sentence) for sentence in brown_corpus]\n",
    "brown_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in brown_corpus][:5000]\n",
    "webtext_corpus = webtext.sents()\n",
    "webtext_corpus = [\" \".join(sentence) for sentence in webtext_corpus]\n",
    "webtext_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in webtext_corpus][:5000]\n",
    "reuters_corpus = reuters.sents()\n",
    "reuters_corpus = [\" \".join(sentence) for sentence in reuters_corpus]\n",
    "reuters_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in reuters_corpus][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unigrams(text):\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract unigrams, bigrams, and trigrams from a corpus\n",
    "def extract_unigrams(corpus):\n",
    "    unigrams = []\n",
    "    for sentence in corpus:\n",
    "        unigrams.extend(generate_unigrams(sentence))\n",
    "    return unigrams\n",
    "\n",
    "def extract_bigrams(unigrams):\n",
    "    return list(zip(unigrams, unigrams[1:]))\n",
    "\n",
    "def extract_trigrams(unigrams):\n",
    "    return list(zip(unigrams, unigrams[1:], unigrams[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating n-grams for Brown corpus\n",
    "unigram_brown = extract_unigrams(brown_corpus[:25])\n",
    "bigram_brown = extract_bigrams(unigram_brown[:25])\n",
    "trigram_brown = extract_trigrams(unigram_brown[:25])\n",
    "\n",
    "# Generating n-grams for Webtext corpus\n",
    "unigram_webtext = extract_unigrams(webtext_corpus[:25])\n",
    "bigram_webtext = extract_bigrams(unigram_webtext[:25])\n",
    "trigram_webtext = extract_trigrams(unigram_webtext[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'The'),\n",
       " ('The', 'Fulton'),\n",
       " ('Fulton', 'County'),\n",
       " ('County', 'Grand'),\n",
       " ('Grand', 'Jury'),\n",
       " ('Jury', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'an'),\n",
       " ('an', 'investigation'),\n",
       " ('investigation', 'of'),\n",
       " ('of', \"Atlanta's\"),\n",
       " (\"Atlanta's\", 'recent'),\n",
       " ('recent', 'primary'),\n",
       " ('primary', 'election'),\n",
       " ('election', 'produced'),\n",
       " ('produced', '``'),\n",
       " ('``', 'no'),\n",
       " ('no', 'evidence'),\n",
       " ('evidence', \"''\"),\n",
       " (\"''\", 'that'),\n",
       " ('that', 'any'),\n",
       " ('any', 'irregularities'),\n",
       " ('irregularities', 'took'),\n",
       " ('took', 'place')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count token frequencies\n",
    "def count_frequencies(tokens):\n",
    "    return Counter(tokens)\n",
    "\n",
    "# Function to count n-gram frequencies\n",
    "def count_ngram_frequencies(ngrams):\n",
    "    return Counter(ngrams)\n",
    "\n",
    "# Function to get count of a specific n-gram\n",
    "def get_ngram_count(ngram, ngram_list):\n",
    "    return ngram_list.count(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional probability for bigrams\n",
    "def bigram_probability(w1, w2, bigram_list, unigram_list):\n",
    "    bigram = (w1, w2)\n",
    "    bigram_count = get_ngram_count(bigram, bigram_list)\n",
    "    unigram_count = unigram_list.count(w1)\n",
    "    return (bigram_count + 1) / (unigram_count + len(set(unigram_list)))\n",
    "\n",
    "# Conditional probability for trigrams\n",
    "def trigram_probability(w1, w2, w3, trigram_list, bigram_list, unigram_list):\n",
    "    trigram = (w1, w2, w3)\n",
    "    trigram_count = get_ngram_count(trigram, trigram_list)\n",
    "    bigram_count = get_ngram_count((w1, w2), bigram_list)\n",
    "    return (trigram_count + 1) / (bigram_count + len(set(unigram_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate bigram perplexity\n",
    "def bigram_perplexity(sentence, unigrams, bigrams):\n",
    "    words = generate_unigrams(sentence)\n",
    "    unigram_counts = Counter(unigrams)\n",
    "    N = len(words)\n",
    "    prob = unigram_counts[words[0]] / N\n",
    "    for i in range(1, N):\n",
    "        prob *= bigram_probability(words[i-1], words[i], bigrams, unigrams)\n",
    "    return (1 / prob) ** (1 / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate trigram perplexity\n",
    "def trigram_perplexity(sentence, unigrams, bigrams, trigrams):\n",
    "    words = generate_unigrams(sentence)\n",
    "    N = len(words)\n",
    "    prob = bigram_probability(words[0], words[1], bigrams, unigrams)\n",
    "    for i in range(2, N):\n",
    "        prob *= trigram_probability(words[i-2], words[i-1], words[i], trigrams, bigrams, unigrams)\n",
    "    return (1 / prob) ** (1 / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram perplexity for first 5 Brown corpus sentences 241.52576419085705\n"
     ]
    }
   ],
   "source": [
    "# Compute bigram perplexity for first 5 Brown corpus sentences\n",
    "perplexity = sum(bigram_perplexity(sent, unigram_brown, bigram_brown) for sent in brown_corpus[:5])\n",
    "print(\"bigram perplexity for first 5 Brown corpus sentences\",perplexity / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram perplexity for first 5 Brown corpus sentences 231.80852210203474\n"
     ]
    }
   ],
   "source": [
    "# Compute trigram perplexity for first 5 Brown corpus sentences\n",
    "perplexity = sum(trigram_perplexity(sent, unigram_brown, bigram_brown, trigram_brown) for sent in brown_corpus[:5])\n",
    "print(\"trigram perplexity for first 5 Brown corpus sentences\",perplexity / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram perplexity for first 25 Reuters corpus sentences using Webtext model 664.6676696435447\n"
     ]
    }
   ],
   "source": [
    "# Compute bigram perplexity for first 25 Reuters corpus sentences using Webtext model\n",
    "perplexity = sum(bigram_perplexity(sent, unigram_webtext, bigram_webtext) for sent in reuters_corpus[:25])\n",
    "print(\"bigram perplexity for first 25 Reuters corpus sentences using Webtext model\",perplexity / 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram perplexity for first 25 Reuters corpus sentences using Brown model 253.5422379735836\n"
     ]
    }
   ],
   "source": [
    "# Compute bigram perplexity for first 25 Reuters corpus sentences using Brown model\n",
    "perplexity = sum(bigram_perplexity(sent, unigram_brown, bigram_brown) for sent in reuters_corpus[:25])\n",
    "print(\"bigram perplexity for first 25 Reuters corpus sentences using Brown model\",perplexity / 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
